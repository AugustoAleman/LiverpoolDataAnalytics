{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Machine Learning para el etiquetado de empleados dentro de Liverpool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    * Autor: Octavio Augusto Alemán Esparza\n",
    "    * fecha: 12.11.2023\n",
    "    * Titulo: model.ipynb\n",
    "    * Descripción: Funciones para el modelado y etiquetado de empleados renunciantes dentro de Liverpool\n",
    "'''\n",
    "\n",
    "import pandas as pd #libreria standard para el manejo de datos\n",
    "import numpy as np  #libreria standard para operaciones matemáticas\n",
    "import matplotlib.pyplot as plt #libreria base para visualización de datos\n",
    "import seaborn as sns #libreria avanzada para visualización de datos\n",
    "from itertools import combinations\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import statistics\n",
    "import warnings\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#plotting some predictions\n",
    "from sklearn import tree\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de archivos\n",
    "file_path = './data/'\n",
    "\n",
    "# Nombre de archivo\n",
    "file_name = 'data_for_model.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos a un Dataframe\n",
    "df = pd.read_csv(file_path + file_name)\n",
    "\n",
    "# Definición de la primera columna como index\n",
    "df.set_index(df.columns[0], inplace=True)\n",
    "df.index.name = 'index'\n",
    "\n",
    "# Visualización de las primeras 5 entradas\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de columnas categóricas a numericas\n",
    "def dataToNumeric(df):\n",
    "\n",
    "    df_categoric = df.select_dtypes(exclude= ['number'])\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in range (0, len(df_categoric.columns)):\n",
    "        df[df_categoric.columns[col]] = label_encoder.fit_transform(df[df_categoric.columns[col]])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = dataToNumeric(df)\n",
    "\n",
    "# Visualización de resultados\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sondeo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analísis de Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showCorr(df):\n",
    "\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    df_aux.columns = [col[:10] for col in df_aux.columns]\n",
    "\n",
    "    # Calcula la matriz de correlación\n",
    "    correlation_matrix = df_aux.corr()\n",
    "\n",
    "    # Crea un gráfico de mapa de calor con Plotly\n",
    "    fig = px.imshow(correlation_matrix,\n",
    "                    color_continuous_scale='PuRd',  # Utiliza una paleta de colores en tonos de rosa\n",
    "                    title='Mapa de Calor de Correlación')\n",
    "    \n",
    "    fig.update_layout(title_x = 0.5)\n",
    "\n",
    "    return fig.show()\n",
    "\n",
    "showCorr(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desviación estándar - Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "def zScore():\n",
    "    cols = list(df.columns)\n",
    "    cols.pop() \n",
    "    z = np.abs(stats.zscore(df[cols]))\n",
    "\n",
    "    return z\n",
    "\n",
    "zScore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución de activos y renuncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populationDistribution():\n",
    "    # Poblacion activa\n",
    "    act = df[df['clase'] == 0]\n",
    "\n",
    "    # Población renuncias\n",
    "    res = df[df['clase'] == 1]\n",
    "\n",
    "    # Cantidad por población\n",
    "    num_act = len(act)\n",
    "    num_res = len(res)\n",
    "\n",
    "    # Rango normalizado\n",
    "    act_range = np.arange(num_act) / num_act * 100\n",
    "    res_range = np.arange(num_res) / num_res * 100\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    #cols.remove('Estado')\n",
    "    cols.pop()\n",
    "\n",
    "    # Filas del subplot\n",
    "    rows = int(np.ceil(len(cols) / 3))\n",
    "\n",
    "    fig = sp.make_subplots(rows=rows, cols=3)\n",
    "\n",
    "    for i, column in enumerate(cols):\n",
    "\n",
    "        # Ordenar valores de columna actual\n",
    "        act_col = act[column].sort_values()\n",
    "        res_col = res[column].sort_values()\n",
    "\n",
    "        row_num = i // 3 + 1\n",
    "        col_num = i % 3 + 1\n",
    "\n",
    "        legend = False\n",
    "\n",
    "        if row_num == 3 and col_num == 3:\n",
    "            legend = True\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=act_col, \n",
    "                                 y=act_range, \n",
    "                                 name=\"Activos\", \n",
    "                                 mode='lines', \n",
    "                                 marker=dict(color='#CD137A'),\n",
    "                                 legendgroup=\"Activos\",\n",
    "                                 legendgrouptitle_text=\"Activos\",\n",
    "                                 showlegend=legend), row=row_num, col=col_num)\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=res_col, \n",
    "                                 y=res_range, \n",
    "                                 name=\"Renuncias\", \n",
    "                                 mode='lines', \n",
    "                                 marker=dict(color='#EEAABF'),\n",
    "                                 legendgroup=\"Renuncias\",\n",
    "                                 legendgrouptitle_text=\"Renuncias\",\n",
    "                                 showlegend=legend), row=row_num, col=col_num)\n",
    "\n",
    "        fig.update_xaxes(title_text=column, \n",
    "                         row=row_num, \n",
    "                         col=col_num, \n",
    "                         showline=True, \n",
    "                         showgrid=False, \n",
    "                         showticklabels=True)\n",
    "        \n",
    "        fig.update_yaxes(row=row_num, \n",
    "                         col=col_num, \n",
    "                         showline=True, \n",
    "                         showgrid=False)\n",
    "\n",
    "    fig.update_layout(\n",
    "            showlegend=True,\n",
    "            height=300 * rows,\n",
    "            width=1000,\n",
    "            title='Distribución de activos y renuncias',\n",
    "            title_x=0.5,\n",
    "        )\n",
    "    \n",
    "    return fig.show()\n",
    "\n",
    "populationDistribution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución de activos y renuncias - Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populationDistributionHist():\n",
    "    # Poblacion activa\n",
    "    act = df[df['clase'] == 0]\n",
    "\n",
    "    # Población renuncias\n",
    "    res = df[df['clase'] == 1]\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    #cols.remove('Estado')\n",
    "    cols.pop()\n",
    "\n",
    "    # Filas y columnas del subplot\n",
    "    rows = int(np.ceil(len(cols) / 3))\n",
    "\n",
    "    fig = sp.make_subplots(rows=rows, cols=3)\n",
    "\n",
    "    for i, column in enumerate(cols):\n",
    "\n",
    "        # Valores de columna actual\n",
    "        act_col = act[column]\n",
    "        res_col = res[column]\n",
    "\n",
    "        row_num = i // 3 + 1\n",
    "        col_num = i % 3 + 1\n",
    "\n",
    "        legend = False\n",
    "\n",
    "        if row_num == 3 and col_num == 3:\n",
    "            legend = True\n",
    "\n",
    "        fig.add_trace(go.Histogram(x=act_col, \n",
    "                                   name=\"Activos\",\n",
    "                                   marker_color='teal',\n",
    "                                   opacity=0.5,\n",
    "                                   legendgroup=\"Activos\",\n",
    "                                   nbinsx=9,\n",
    "                                   showlegend=legend,\n",
    "                                   histnorm='percent'), row=row_num, col=col_num)\n",
    "        \n",
    "        fig.add_trace(go.Histogram(x=res_col, \n",
    "                                   name=\"Renuncias\",\n",
    "                                   marker_color='orange',\n",
    "                                   opacity=0.5,\n",
    "                                   legendgroup=\"Renuncias\",\n",
    "                                   nbinsx=9,\n",
    "                                   showlegend=legend,\n",
    "                                   histnorm='percent'), row=row_num, col=col_num)\n",
    "\n",
    "        fig.update_xaxes(title_text=column, \n",
    "                         row=row_num, \n",
    "                         col=col_num, \n",
    "                         showline=True, \n",
    "                         showgrid=False, \n",
    "                         showticklabels=True)\n",
    "        \n",
    "        fig.update_yaxes(row=row_num, \n",
    "                         col=col_num, \n",
    "                         showline=True, \n",
    "                         showgrid=False)\n",
    "\n",
    "    fig.update_layout(\n",
    "            showlegend=True,\n",
    "            height=300 * rows,\n",
    "            width=1000,\n",
    "            barmode='overlay',  # Superpone los histogramas\n",
    "            title='Distribución de activos y renuncias',\n",
    "            title_x=0.5,\n",
    "        )\n",
    "    \n",
    "    return fig.show()\n",
    "\n",
    "populationDistributionHist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submuestreo aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classProportion():\n",
    "    # Calcula la diferencia en la columna 'Clase'\n",
    "    difference = df['clase'].value_counts()\n",
    "\n",
    "    colors = ['#CD137A', '#EEAABF']\n",
    "\n",
    "    # Crea un gráfico de barras\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(x=difference.index, \n",
    "               y=difference.values,\n",
    "               marker_color=colors)\n",
    "    ])\n",
    "\n",
    "    # Configura el diseño del gráfico\n",
    "    fig.update_layout(\n",
    "        title='Distribución de Clases',\n",
    "        title_x = 0.5,\n",
    "        xaxis_title='Clase',\n",
    "        yaxis_title='Total',\n",
    "    )\n",
    "\n",
    "    # Muestra el gráfico\n",
    "    return fig.show()\n",
    "\n",
    "classProportion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aleatorizar y particionar la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1, random_state=57)\n",
    "\n",
    "def removeClass(df, class_to_drop, n):\n",
    "    df_aux = df.copy()\n",
    "\n",
    "    to_remove = df_aux[df_aux['clase'] == class_to_drop]\n",
    "    to_remove = to_remove.sample(frac = 1, random_state = 27)\n",
    "\n",
    "    df_aux = df_aux.drop(to_remove.head(n).index)\n",
    "\n",
    "    return df_aux\n",
    "\n",
    "# Eliminar aleatoriamente N muestras\n",
    "N = 95000\n",
    "\n",
    "# Clase a eliminar (Renucnias)\n",
    "drop_class = 1\n",
    "\n",
    "# Remover filas\n",
    "df = removeClass(df, 1, N)\n",
    "\n",
    "# Visualización del Dataframe\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nueva Distribución de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classProportion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['genero', 'sindicato', 'edad ingreso', 'edad salida'], axis = 1, inplace = True)\n",
    "\n",
    "# Visualización del dataframe\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización\n",
    "n_colsX = df.shape[1] - 1\n",
    "\n",
    "X = df.iloc[:,0:n_colsX]\n",
    "Y = df.iloc[:,n_colsX] \n",
    "\n",
    "rescaledX = StandardScaler().fit_transform(X)\n",
    "newX    = pd.DataFrame(data=rescaledX,columns=X.columns)\n",
    "\n",
    "# Nuevos datos escalados\n",
    "newX.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columna de Clase\n",
    "Y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División de datos en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de conjuntos de entrenamiento y prueba\n",
    "test_size = 0.2\n",
    "rnd_state = 66\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(newX, \n",
    "                                                    Y, \n",
    "                                                    random_state=rnd_state, \n",
    "                                                    test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de prueba\n",
    "X_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de Modelos\n",
    "models = []\n",
    "\n",
    "# Definición de odelos\n",
    "\n",
    "#Naive Bayes\n",
    "models.append(('Naive Bayes', GaussianNB()))\n",
    "\n",
    "# KNN\n",
    "models.append(('KNN, K = 5', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('KNN, K = 7', KNeighborsClassifier(n_neighbors=7)))\n",
    "models.append(('KNN, K = 9', KNeighborsClassifier(n_neighbors=9)))\n",
    "\n",
    "# Árboles de decisión\n",
    "models.append(('CART with gini', DecisionTreeClassifier(criterion='gini')))\n",
    "models.append(('CART with entropy', DecisionTreeClassifier(criterion='entropy')))\n",
    "models.append(('CART with entropy and max_depth: 3', DecisionTreeClassifier(criterion='entropy', max_depth=3)))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('Decision Tree with entropy', DecisionTreeClassifier(criterion='entropy')))\n",
    "\n",
    "# MLP\n",
    "models.append(('MLP Adam Identity, 5x2', MLPClassifier(solver='adam', hidden_layer_sizes= (5,2), max_iter=5000, activation = 'identity')))\n",
    "\n",
    "# SVM\n",
    "models.append(('SVM RBF 3', SVC(kernel='rbf', C=0.5, gamma='auto', probability=True)))\n",
    "models.append(('SVM RBF 4', SVC(kernel='rbf', C=0.5, gamma=0.07, probability=True)))\n",
    "models.append(('SVM Linear 2', SVC(kernel='linear', C=0.5, probability=True)))\n",
    "models.append(('SVM Poly 2', SVC(kernel='poly', degree=1, C=0.05,  probability=True)))\n",
    "models.append(('SVM Poly 4', SVC(kernel='poly', degree=3, C=0.9,  probability=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenando los modelos\n",
    "results=[]\n",
    "names=[]\n",
    "\n",
    "#Barra de progreso\n",
    "total_iterations = len(models)\n",
    "with tqdm(total=total_iterations, desc=\"Cargando\") as pbar:\n",
    "  # Entrenamiento de cada modelo\n",
    "  for name,model in models:\n",
    "    kfold=KFold(n_splits=10,shuffle=True)\n",
    "    cv_result=cross_val_score(model,X_train,Y_train,cv=kfold,scoring='accuracy')\n",
    "    names.append(name)\n",
    "    results.append(cv_result)\n",
    "\n",
    "    # Actualiza la barra de progreso\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Proceso completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de resultados\n",
    "for i in range(len(names)):\n",
    "  total=int((1-test_size)*100)\n",
    "  print(f'{names[i]} entrenado con una precisión del: {round((results[i].mean() * 100), 2)}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot con los resultados por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplotModelResults():\n",
    "    # Paleta de colores\n",
    "    colors_extended = ['#CD137A', \n",
    "                       '#D12A84', \n",
    "                       '#D5408E', \n",
    "                       '#D95797', \n",
    "                       '#DD6DA1', \n",
    "                       '#E184AB', \n",
    "                       '#E59BB5', \n",
    "                       '#E9B1BF', \n",
    "                       '#EDC8C8', \n",
    "                       '#F1DED2', \n",
    "                       '#F5F5DC']\n",
    "\n",
    "    # Obtención de las medianas\n",
    "    medians = []\n",
    "    for i in range(len(results)):\n",
    "        medians.append(round(statistics.median(results[i]), 3))\n",
    "\n",
    "    # Crear una figura y un eje\n",
    "    fig, ax = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "    # Usar la paleta de colores en el gráfico de caja\n",
    "    sns.boxplot(data=results, ax=ax, palette=colors_extended)\n",
    "\n",
    "    ax.set_xticklabels(names)\n",
    "    vertical_offset = statistics.median(medians) * 0.01\n",
    "    for xtick in ax.get_xticks():\n",
    "        ax.text(xtick, medians[xtick] + vertical_offset, \n",
    "                medians[xtick], \n",
    "                horizontalalignment='center', \n",
    "                color='black', \n",
    "                weight='semibold')\n",
    "\n",
    "    plt.title('Precisión para modelos en fase entrenamiento', fontsize=20, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    return plt.show()\n",
    "\n",
    "boxplotModelResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba de modelos - Matrices de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"Activos\", \"Renuncias\"]\n",
    "FPR = []  # false positives rates vector\n",
    "TPR = []  # true positives rates vector\n",
    "TRESH = []  # threshold rates vector\n",
    "Y_scores = []  # prediction in each point\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predict = model.predict(X_test)\n",
    "    print(f'Evaluando {name} con los datos de prueba')\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "    # confusion matrix\n",
    "    confusion = confusion_matrix(Y_test, Y_predict)\n",
    "    sns.heatmap(confusion, annot=True, xticklabels=label, yticklabels=label, fmt='', cmap='Blues')  # Cambio de colores a rosas\n",
    "    plt.show()\n",
    "    \n",
    "    # taking the important values from confusion matrix\n",
    "    TP = confusion[1, 1]  # True Positives (TP)\n",
    "    TN = confusion[0, 0]  # True Negatives (TN)\n",
    "    FP = confusion[0, 1]  # False Positives (FP) a \"Type I error\"\n",
    "    FN = confusion[1, 0]  # False Negatives (FN) a \"Type II error\"\n",
    "    \n",
    "    # Classification Accuracy: Overall, how often is the classifier correct?\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print(f'ACC: {acc:.2f}')\n",
    "    \n",
    "    # Classification Error: Overall, how often is the classifier incorrect?\n",
    "    error_rate = (FP + FN) / (TP + TN + FP + FN)\n",
    "    print(f'Misclassification Rate: {error_rate:.2f}')\n",
    "    \n",
    "    # Sensitivity (recall): When the actual value is positive, how often is the prediction correct?\n",
    "    recall = TP / (TP + FN)\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    \n",
    "    # Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "    precision = TP / (TP + FP)\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "\n",
    "    # F1-score\n",
    "    f1 = f1_score(Y_test, Y_predict)\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "    \n",
    "    # For ROC\n",
    "    Y_score = model.predict_proba(X_test)[:, 1]  # Predictions in all points\n",
    "    Y_scores.append(Y_score)\n",
    "    \n",
    "    FP_rates, TP_rates, Tresh_rates = roc_curve(Y_test, Y_score)\n",
    "    FPR.append(FP_rates)\n",
    "    TPR.append(TP_rates)\n",
    "    TRESH.append(Tresh_rates)\n",
    "    \n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Visual de Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting ROC\n",
    "markers = ['.', ',', 'o', 'v', '^', '>', '<', '*', '1', '2', '3', '4', '8', 's', 'p', 'P', 'h', 'H', '+', 'x', '|', '_', '_', 'x','1', '2', '3','.', ',', 'o', 'v', '^', '>','8', 's', 'p', 'P', 'h', 'H', '+', 'x', '|', '_', '_', 'x','1']\n",
    "lines = ['-', '--', '-.', ':', '-', '--', '-.', ':', '-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':', '-', '--', '-.', ':', '-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':' ,'-', '--', '-.', ':', '-', '--', '-.', ':', '-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':','-', '--', '-.', ':'  ]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in range(len(names)):\n",
    "  plt.plot(FPR[i], TPR[i], label=names[i], marker=markers[i], linestyle=lines[i])\n",
    "\n",
    "#plotting reference line\n",
    "sns.lineplot(x = [0, 1], y = [0, 1], color = 'red')\n",
    "plt.xlim(-0.05, 1.05)\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.xlabel('False positives rate',fontsize=16)\n",
    "plt.ylabel('True positives rate',fontsize=16)\n",
    "plt.title('ROC', fontsize=28)\n",
    "plt.legend(fontsize=16, loc=4)\n",
    "plt.show()\n",
    "\n",
    "#printing AUC\n",
    "print('ROC-AUC')\n",
    "print('----')\n",
    "for i in range(len(names)):\n",
    "  print(f'ROC-AUC for {names[i]}: {roc_auc_score(Y_test, Y_scores[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting precision-recall curve\n",
    "plt.figure(figsize=(12,8))\n",
    "displays = []\n",
    "i = 0\n",
    "\n",
    "for name, model in models:\n",
    "  precisionCurve, recallCurve, _ = precision_recall_curve(Y_test, Y_scores[i])\n",
    "  displays.append(PrecisionRecallDisplay(precision=precisionCurve, recall=recallCurve, estimator_name=name))\n",
    "  displays[i].plot(ax=plt.gca())\n",
    "  i = i + 1\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Recall',fontsize=16)\n",
    "plt.ylabel('Precision',fontsize=16)\n",
    "plt.title('PR Curve', fontsize=28)\n",
    "plt.legend(fontsize=12, loc=4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espacios de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting classification space\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(rescaledX)\n",
    "Y_plot = df['clase'].astype(int).values\n",
    "\n",
    "for name,model in models:\n",
    "  print(f'Modelando con:  {name}')\n",
    "  model_short = model\n",
    "  model_short.fit(X_pca, Y_plot)\n",
    "  plot_decision_regions(X_pca, Y_plot, clf=model_short, legend = 2 )\n",
    "  plt.xlabel('X')\n",
    "  plt.ylabel('Y')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importancia de Atributos\n",
    "* Para los modelos con mejor rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labels = np.array(list(df.columns[:-1]))\n",
    "\n",
    "for name,model in models:\n",
    "  if 'Random' in name:\n",
    "      \n",
    "      '''model.fit(X_train, Y_train)\n",
    "      Y_predict = model.predict(X_test)'''\n",
    "  \n",
    "      print('_____________________________________')\n",
    "      print(f'Modelando con:  {name}')\n",
    "\n",
    "      importance = model.feature_importances_\n",
    "      feature_indexes_by_importance = importance.argsort()\n",
    "      for index in feature_indexes_by_importance:\n",
    "            print('{} - {:.2f}%'.format(str(feature_labels[index]).capitalize(), (importance[index] *100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionamiento del modelo\n",
    "* Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df[df['clase'] == 1].sample(10).copy()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_risk(df):\n",
    "    for name, model in models:\n",
    "        if 'Random' in name:\n",
    "            \n",
    "            aux = df.copy()\n",
    "\n",
    "            # Normalización\n",
    "            n_colsX = aux.shape[1]-1\n",
    "            X = df.iloc[:,0:n_colsX]\n",
    "            rescaledX = StandardScaler().fit_transform(X)\n",
    "            newX    = pd.DataFrame(data=rescaledX,columns=X.columns)\n",
    "\n",
    "            # Utilizar el modelo para predecir probabilidades de la clase positiva\n",
    "            Y_probabilities = model.predict_proba(newX)[:, 1]\n",
    "\n",
    "            # Definir umbrales de riesgo\n",
    "            low_threshold = 0.6\n",
    "            medium_threshold = 0.8\n",
    "\n",
    "            # Asignar niveles de riesgo\n",
    "            risk_levels = []\n",
    "\n",
    "            for score in Y_probabilities:\n",
    "                if score < low_threshold:\n",
    "                    risk_levels.append(\"Riesgo Bajo\")\n",
    "                elif low_threshold <= score < medium_threshold:\n",
    "                    risk_levels.append(\"Riesgo Medio\")\n",
    "                else:\n",
    "                    risk_levels.append(\"Riesgo Alto\")\n",
    "\n",
    "            # Agregar los niveles de riesgo al DataFrame\n",
    "            df['Nivel de Riesgo'] = risk_levels\n",
    "\n",
    "    return df\n",
    "\n",
    "identify_risk(test_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
